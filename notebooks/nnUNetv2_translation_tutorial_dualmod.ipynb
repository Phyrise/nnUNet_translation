{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------- How to : build a nnUNet_translation dataset -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1 --- 5 ['data/mr/1PA070.nii.gz', 'data/mr/1PA073.nii.gz', 'data/mr/1PA074.nii.gz', 'data/mr/1PA076.nii.gz', 'data/mr/1PA079.nii.gz']\n",
      "input2 --- 5 ['data/mask/1PA070.nii.gz', 'data/mask/1PA073.nii.gz', 'data/mask/1PA074.nii.gz', 'data/mask/1PA076.nii.gz', 'data/mask/1PA079.nii.gz']\n",
      "target --- 5 ['data/ct/1PA070_0000.nii.gz', 'data/ct/1PA073_0000.nii.gz', 'data/ct/1PA074_0000.nii.gz', 'data/ct/1PA076_0000.nii.gz', 'data/ct/1PA079_0000.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import shutil, json, glob, os\n",
    "from tqdm import tqdm \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "data1_dir = 'data/mr/'\n",
    "data2_dir = 'data/mask/'\n",
    "target_dir = 'data/ct/'\n",
    "\n",
    "os.environ['nnUNet_results'] = 'results/'\n",
    "os.environ['nnUNet_raw'] = 'raw/'\n",
    "os.environ['nnUNet_preprocessed'] = 'preprocessed/'\n",
    "\n",
    "# example with 2 input modalities\n",
    "list_datas1 = sorted(glob.glob(os.path.join(data1_dir, '*.nii.gz')))\n",
    "list_datas2 = sorted(glob.glob(os.path.join(data2_dir, '*.nii.gz')))\n",
    "list_targets = sorted(glob.glob(os.path.join(target_dir, '*.nii.gz')))\n",
    "\n",
    "print(\"input1 ---\", len(list_datas1), list_datas1)\n",
    "print(\"input2 ---\", len(list_datas2), list_datas2)\n",
    "print(\"target ---\", len(list_targets), list_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define dataset ID and make paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 60 # /!\\ we will use both the dataset_id and the dataset_id + 1 \n",
    "dataset_data_name = 'SynthRAD2023_Pelvis_MR_mask'\n",
    "dataset_target_name = 'SynthRAD2023_Pelvis_CT'\n",
    "\n",
    "# we will copy the datas\n",
    "# do not use exist_ok=True, we want an error if the dataset exist already\n",
    "dataset_data_path = os.path.join(os.environ['nnUNet_raw'], f'Dataset{dataset_id:03d}_{dataset_data_name}') \n",
    "os.makedirs(dataset_data_path, exist_ok = True)\n",
    "os.makedirs(os.path.join(dataset_data_path, 'imagesTr'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_data_path, 'labelsTr'), exist_ok = True)\n",
    "\n",
    "dataset_target_path = os.path.join(os.environ['nnUNet_raw'], f'Dataset{dataset_id+1:03d}_{dataset_target_name}') \n",
    "os.makedirs(dataset_target_path, exist_ok = True)\n",
    "os.makedirs(os.path.join(dataset_target_path, 'imagesTr'), exist_ok = True)\n",
    "os.makedirs(os.path.join(dataset_target_path, 'labelsTr'), exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy files and create dummy masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.22s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.12s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_file(data_path, dataset_path, mat, modality_suffix=\"_0000\"):\n",
    "    curr_nifti = nib.load(data_path)\n",
    "    filename = os.path.basename(data_path)\n",
    "    if not filename.endswith(f'{modality_suffix}.nii.gz'):\n",
    "        filename = filename.replace('.nii.gz', f'{modality_suffix}.nii.gz')\n",
    "    curr_nifti.to_filename(os.path.join(dataset_path, f'imagesTr/{filename}'))\n",
    "\n",
    "    data = curr_nifti.get_fdata()\n",
    "    # Adjust the mask as needed for your specific use case. By default, the mask is set to 1 for the entire volume.\n",
    "    # This will be used for foreground preprocessing, cf https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/explanation_normalization.md\n",
    "    data = np.ones_like(data)\n",
    "\n",
    "    filename = filename.replace(modality_suffix, '')  # Remove modality suffix for masks\n",
    "    if not os.path.exists(os.path.join(dataset_path, f'labelsTr/{filename}')):\n",
    "        nib.Nifti1Image(data, mat).to_filename(os.path.join(dataset_path, f'labelsTr/{filename}')) \n",
    "\n",
    "mat = nib.load(list_datas1[-1]).affine\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(lambda data_path: process_file(data_path, dataset_data_path, mat, \"_0000\"), list_datas1), total=len(list_datas1)))\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(lambda data_path: process_file(data_path, dataset_data_path, mat, \"_0001\"), list_datas2), total=len(list_datas2)))\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(lambda target_path: process_file(target_path, dataset_target_path, mat), list_targets), total=len(list_targets)))\n",
    "\n",
    "#### without multithreading\n",
    "# for data_path in tqdm(list_datas, total=len(list_datas)):\n",
    "#     process_file(data_path, dataset_data_path, mat)\n",
    "\n",
    "# for target_path in tqdm(list_targets, total=len(list_targets)):\n",
    "#     process_file(target_path, dataset_target_path, mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ you will need to edit this with regards to the number of modalities used;\n",
    "data_dataset_json = {\n",
    "    \"labels\": {\n",
    "        \"label_001\": \"1\", \n",
    "        \"background\": 0\n",
    "    },\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"MR\",\n",
    "        \"1\": \"mask\",\n",
    "        \n",
    "    },\n",
    "    \"numTraining\": len(list_datas1),\n",
    "    \"file_ending\": \".nii.gz\"\n",
    "}\n",
    "dump_data_datasets_path = os.path.join(dataset_data_path, 'dataset.json')\n",
    "with open(dump_data_datasets_path, 'w') as f:\n",
    "    json.dump(data_dataset_json, f)\n",
    "\n",
    "target_dataset_json = {\n",
    "    \"labels\": {\n",
    "        \"label_001\": \"1\",\n",
    "        \"background\": 0\n",
    "    },\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"CT\",\n",
    "    },\n",
    "    \"numTraining\": len(list_targets),\n",
    "    \"file_ending\": \".nii.gz\"\n",
    "}\n",
    "dump_target_datasets_path = os.path.join(dataset_target_path, 'dataset.json')\n",
    "with open(dump_target_datasets_path, 'w') as f:\n",
    "    json.dump(target_dataset_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply preprocessing and unpacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset060_SynthRAD2023_Pelvis_MR_mask\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment planning...\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5  1.03 1.03]. \n",
      "Current patch size: (np.int64(56), np.int64(160), np.int64(224)). \n",
      "Current median shape: [116.         305.82524272 465.04854369]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5    1.0609 1.0609]. \n",
      "Current patch size: (np.int64(56), np.int64(160), np.int64(224)). \n",
      "Current median shape: [116.         296.91771138 451.50344048]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5      1.092727 1.092727]. \n",
      "Current patch size: (np.int64(64), np.int64(128), np.int64(224)). \n",
      "Current median shape: [116.         288.2696227  438.35285483]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.12550881 1.12550881]. \n",
      "Current patch size: (np.int64(64), np.int64(128), np.int64(224)). \n",
      "Current median shape: [116.         279.87342009 425.58529595]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.15927407 1.15927407]. \n",
      "Current patch size: (np.int64(64), np.int64(128), np.int64(224)). \n",
      "Current median shape: [116.         271.72176708 413.18960772]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5       1.1940523 1.1940523]. \n",
      "Current patch size: (np.int64(64), np.int64(128), np.int64(224)). \n",
      "Current median shape: [116.         263.80754086 401.15495895]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.22987387 1.22987387]. \n",
      "Current patch size: (np.int64(64), np.int64(128), np.int64(224)). \n",
      "Current median shape: [116.         256.12382607 389.47083393]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.26677008 1.26677008]. \n",
      "Current patch size: (np.int64(64), np.int64(160), np.int64(224)). \n",
      "Current median shape: [116.         248.66390881 378.12702324]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.575      1.30477318 1.30477318]. \n",
      "Current patch size: (np.int64(64), np.int64(160), np.int64(224)). \n",
      "Current median shape: [112.62135922 241.42127069 367.11361479]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.65225    1.34391638 1.34391638]. \n",
      "Current patch size: (np.int64(64), np.int64(160), np.int64(224)). \n",
      "Current median shape: [109.34112546 234.38958319 356.42098524]\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [116. 315. 479.], 3d_lowres: [109, 234, 356]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 20, 'patch_size': (np.int64(320), np.int64(512)), 'median_image_size_in_voxels': array([315., 479.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'decoder_type': 'standard'}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(56), np.int64(160), np.int64(224)), 'median_image_size_in_voxels': array([116., 315., 479.]), 'spacing': array([2.5, 1. , 1. ]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'decoder_type': 'standard'}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to preprocessed/Dataset060_SynthRAD2023_Pelvis_MR_mask/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset060_SynthRAD2023_Pelvis_MR_mask\n",
      "Configuration: 3d_fullres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "Fingerprint extraction...\n",
      "Dataset061_SynthRAD2023_Pelvis_CT\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "if 'MPLBACKEND' in os.environ: \n",
    "    del os.environ['MPLBACKEND'] # avoid conflicts with matplotlib backend  \n",
    "    \n",
    "os.system(f'nnUNetv2_plan_and_preprocess -d {dataset_id} -c 3d_fullres')\n",
    "os.system(f'nnUNetv2_unpack {dataset_id} 3d_fullres 0')\n",
    "\n",
    "os.system(f'nnUNetv2_plan_and_preprocess -d {dataset_id + 1} -c 3d_fullres')\n",
    "os.system(f'nnUNetv2_unpack {dataset_id + 1} 3d_fullres 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define 2nd modality raw data as gt_segmentations of 1st modality\n",
    "##### originally used for computing metrics / postprocessing, not sure if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnunet_datas_preprocessed_dir = os.path.join(os.environ['nnUNet_preprocessed'], f'Dataset{dataset_id+1:03d}_{dataset_target_name}') \n",
    "nnunet_targets_preprocessed_dir = os.path.join(os.environ['nnUNet_preprocessed'], f'Dataset{dataset_id:03d}_{dataset_data_name}') \n",
    "\n",
    "list_targets = glob.glob(os.path.join(f\"{dataset_target_path}/imagesTr\", '*'))\n",
    "list_targets.sort()\n",
    "list_gt_segmentations_datas = glob.glob(os.path.join(f\"{nnunet_targets_preprocessed_dir}/gt_segmentations\", '*'))\n",
    "list_gt_segmentations_datas.sort()\n",
    "\n",
    "print(nnunet_targets_preprocessed_dir)\n",
    "\n",
    "for (preprocessed_path, gt_path) in zip(list_targets, list_gt_segmentations_datas):\n",
    "    # here, gt_path is the path to the gt_segmentation in nnUNet_preprocessed.\n",
    "    print(preprocessed_path, \"->\", gt_path) # ensure correct file pairing; \n",
    "    shutil.copy(src = preprocessed_path, dst = gt_path) # we use shutil.copy to ensure safety, but switching to shutil.move would be more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define 2nd modality preprocessed files as ground truth of 1st modality\n",
    "##### used in training, definitely needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_preprocessed_datas_seg_path = sorted(glob.glob(os.path.join(nnunet_targets_preprocessed_dir, 'nnUNetPlans_3d_fullres/*_seg.npy')))\n",
    "\n",
    "list_preprocessed_targets_path = sorted(glob.glob(os.path.join(nnunet_datas_preprocessed_dir, 'nnUNetPlans_3d_fullres/*.npy')))\n",
    "list_preprocessed_targets_path = [name for name in list_preprocessed_targets_path if '_seg' not in name]\n",
    "\n",
    "for (datas_path, targets_path) in zip(list_preprocessed_datas_seg_path, list_preprocessed_targets_path):\n",
    "    print(targets_path, \"->\", datas_path)\n",
    "    shutil.copy(src = targets_path, dst = datas_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That's it!\n",
    "You should be able to start training with : \n",
    "```\n",
    "export nnUNet_raw=\"/data/alonguefosse/nnUNet/raw\"\n",
    "export nnUNet_preprocessed=\"/data/alonguefosse/nnUNet/preprocessed\"\n",
    "export nnUNet_results=\"/data/alonguefosse/nnUNet/results\"\n",
    "\n",
    "nnUNetv2_train 50 3d_fullres 0 -tr nnUNetTrainerMRCT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
